{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m }\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Récupération du contenu HTML de la page principale\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Vérification du statut de la requête\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 747\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\response.py:1040\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\response.py:1187\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1187\u001b[0m chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1188\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[0;32m   1189\u001b[0m     chunk, decode_content\u001b[38;5;241m=\u001b[39mdecode_content, flush_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m )\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoded:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\response.py:1129\u001b[0m, in \u001b[0;36mHTTPResponse._handle_chunk\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m   1127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left:\n\u001b[1;32m-> 1129\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m-\u001b[39m amt\n\u001b[0;32m   1131\u001b[0m     returned_chunk \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py:626\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    624\u001b[0m s \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 626\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAXAMOUNT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[0;32m    628\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(s), amt)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1241\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# URL de la page principale\n",
    "url = \"https://www.avito.ma/fr/maroc/voitures_d_occasion-%C3%A0_vendre\"\n",
    "\n",
    "\n",
    "# En-têtes pour éviter le blocage du site\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Récupération du contenu HTML de la page principale\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Vérification du statut de la requête\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Trouver tous les liens sur la page principale\n",
    "    div_principal = soup.find(\"div\", {'class':'sc-1nre5ec-1 crKvIr listing'})\n",
    "    liens = div_principal.find_all(\"a\", href=True)\n",
    "\n",
    "    # Filtrer les liens qui commencent par \"/fr/\" (qui sont des liens relatifs pour les annonces)\n",
    "    # liens_annonces = [urljoin(url, lien[\"href\"]) for lien in liens if lien[\"href\"].startswith(\"/fr/\")]\n",
    "\n",
    "    # Afficher les liens extraits\n",
    "    for lien in liens:\n",
    "        print(f\"Accès à l'annonce : {lien['href']}\")\n",
    "        \n",
    "        # Récupérer les détails pour chaque annonce\n",
    "        annonce_response = requests.get(lien[\"href\"], headers=headers)\n",
    "        \n",
    "        if annonce_response.status_code == 200:\n",
    "            annonce_soup = BeautifulSoup(annonce_response.text, \"html.parser\")\n",
    "            \n",
    "            # Extraction des informations du div principal dans l'annonce\n",
    "            div_annonce = annonce_soup.find(\"div\", class_=\"sc-1g3sn3w-8 ePtCCn\")\n",
    "\n",
    "            if div_annonce:\n",
    "                # Extraire le titre dans le <h1>\n",
    "                titre = div_annonce.find(\"h1\").text.strip() \n",
    "\n",
    "                # Extraire la description dans le <p>\n",
    "                description = div_annonce.find(\"p\").text.strip()\n",
    "            \n",
    "                div = annonce_soup.find(\"div\", class_=\"sc-1g3sn3w-7 bNWHpB\")\n",
    "\n",
    "                # Extraire le texte dans le premier <span>\n",
    "                span1 = div.find_all(\"span\")[0].text.strip()\n",
    "\n",
    "                # Extraire le texte dans le deuxième <span>\n",
    "                span2 = div.find_all(\"span\")[1].text.strip() \n",
    "\n",
    "                # Extractions des ifos suplimentaires\n",
    "                div_infos_sup = annonce_soup.find(\"div\", class_=\"sc-6p5md9-0 dsWaSi\")\n",
    "                if div_infos_sup:\n",
    "\n",
    "                    # annee de voiture\n",
    "                    anne=div_infos_sup.find_all(\"span\")[0].text.strip()\n",
    "                    # Type du voiture AUTO/MANUEL\n",
    "                    auto_manuel=div_infos_sup.find_all(\"span\")[1].text.strip()\n",
    "                    \n",
    "                    # Type de V Diesl/Hybride\n",
    "                    diesl_hybr=div_infos_sup.find_all(\"span\")[2].text.strip()\n",
    "                    \n",
    "                # Extraction du donnees de voiture\n",
    "                div_infos_sup_2 = annonce_soup.find(\"ol\", class_=\"sc-qmn92k-3 hTEaGJ\")\n",
    "                if div_infos_sup_2:\n",
    "                    elements_liste = div_infos_sup_2.find_all(\"li\")\n",
    "                    type = elements_liste[0].find_all(\"span\")[1].text.strip()\n",
    "                    secteur = elements_liste[1].find_all(\"span\")[1].text.strip()\n",
    "                    kilometrage = elements_liste[2].find_all(\"span\")[1].text.strip()\n",
    "                    marque = elements_liste[3].find_all(\"span\")[1].text.strip()\n",
    "                    modele = elements_liste[4].find_all(\"span\")[1].text.strip()\n",
    "                    n_portes = elements_liste[5].find_all(\"span\")[1].text.strip()\n",
    "                    origine = elements_liste[6].find_all(\"span\")[1].text.strip()\n",
    "                    p_main = elements_liste[7].find_all(\"span\")[1].text.strip()\n",
    "                    p_fiscale = elements_liste[8].find_all(\"span\")[1].text.strip()\n",
    "                    etat = elements_liste[9].find_all(\"span\")[1].text.strip()\n",
    "                    \n",
    "            # Afficher les informations extraites\n",
    "                print(f\"Titre : {titre}\")\n",
    "                print(f\"Description : {description}\")\n",
    "                print(f\"Date d'ajout : {span2}\")\n",
    "                print(f\"Localisation : {span1}\")\n",
    "                print(f\"la anne : {anne}\")\n",
    "                print(f\"auto ou manul : {auto_manuel}\")\n",
    "                print(f\"type disel ou hyb : {diesl_hybr}\")\n",
    "                print(f\"Type : {type}\")\n",
    "                print(f\"Secteur: {secteur}\")\n",
    "                print(f\"Kilometrage : {kilometrage}\")\n",
    "                print(f\"Marque : {marque}\")\n",
    "                print(f\"Modele : {modele}\")\n",
    "                print(f\"Nombre de portes: {n_portes}\")\n",
    "                print(f\"Origine : {origine}\")\n",
    "                print(f\"Premier main : {p_main}\")\n",
    "                print(f\"Puissance fiscale : {p_fiscale}\")\n",
    "                print(f\"Etat : {etat}\")\n",
    "                print(\"=\"*50)    \n",
    "                \n",
    "            else:\n",
    "                print(f\"Div principal non trouvé pour l'annonce : {lien}\")\n",
    "      \n",
    "        else:\n",
    "            print(f\"Erreur de chargement pour l'annonce : {lien}\")\n",
    "            \n",
    "else:\n",
    "    print(\"Erreur de chargement de la page principale :\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Scraping terminé et données enregistrées dans le fichier CSV !\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Chemin du fichier CSV\n",
    "csv_file_path = r\"C:\\Users\\HP\\Desktop\\projet ai\\mini projet 2\\avito_voitures - Copy - Copy.csv\"\n",
    "\n",
    "# En-têtes CSV\n",
    "csv_headers = [\n",
    "    \"Titre\", \"Prix\", \"Date d'ajout\", \"Localisation\",\"Annee\",\"Auto_manuel\",\"Carburant\", \"Type\", \"Secteur\", \n",
    "    \"Kilométrage\", \"Marque\", \"Modèle\", \"Nombre de portes\", \"Origine\", \n",
    "    \"Première main\", \"Puissance fiscale\", \"État\", \n",
    "]\n",
    "\n",
    "# URL de base\n",
    "base_url = \"https://www.avito.ma/fr/casablanca/voitures_d_occasion-%C3%A0_vendre\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def get_page_content(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, allow_redirects=True)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            print(f\"❌ Erreur {response.status_code} sur : {url}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Exception pour {url} : {e}\")\n",
    "    return None\n",
    "\n",
    "# Initialiser le CSV\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(csv_headers)  # Écrire les en-têtes\n",
    "\n",
    "    # Scraper les pages\n",
    "    for page in range(41, 2):\n",
    "        url = f\"{base_url}?o={page}\"\n",
    "        print(f\"\\n🔎 Scraping de la page {page}: {url}\")\n",
    "        page_content = get_page_content(url)\n",
    "        if not page_content:\n",
    "            continue\n",
    "\n",
    "        soup = BeautifulSoup(page_content, \"html.parser\")\n",
    "        div_principal = soup.find(\"div\", class_='sc-1nre5ec-1 crKvIr listing')\n",
    "        if not div_principal:\n",
    "            print(f\"⚠️ Pas d'annonces trouvées sur la page {page}\")\n",
    "            continue\n",
    "\n",
    "        annonces = div_principal.find_all(\"a\", href=True)\n",
    "        if not annonces:\n",
    "            print(f\"⚠️ Aucune annonce trouvée sur la page {page}\")\n",
    "            continue\n",
    "\n",
    "        for annonce in annonces:\n",
    "            annonce_url = annonce[\"href\"]\n",
    "            if annonce_url.startswith(\"/\"):\n",
    "                annonce_url = \"https://www.avito.ma\" + annonce_url\n",
    "\n",
    "            print(f\"📌 Traitement de l'annonce : {annonce_url}\")\n",
    "            annonce_content = get_page_content(annonce_url)\n",
    "            if not annonce_content:\n",
    "                continue\n",
    "\n",
    "            annonce_soup = BeautifulSoup(annonce_content, \"html.parser\")\n",
    "            div_annonce = annonce_soup.find(\"div\", class_=\"sc-1g3sn3w-8 ePtCCn\")\n",
    "\n",
    "            if not div_annonce:\n",
    "                print(f\"⚠️ Aucune donnée trouvée pour l'annonce {annonce_url}\")\n",
    "                continue\n",
    "\n",
    "            # Extraction des infos principales\n",
    "            titre = div_annonce.find(\"h1\").text.strip() if div_annonce.find(\"h1\") else \"N/A\"\n",
    "            prix = div_annonce.find(\"p\").text.strip() if div_annonce.find(\"p\") else \"N/A\"\n",
    "            \n",
    "            div = annonce_soup.find(\"div\", class_=\"sc-1g3sn3w-7 bNWHpB\")\n",
    "            date_ajout = div.find_all(\"span\")[1].text.strip() if div else \"N/A\"\n",
    "            localisation = div.find_all(\"span\")[0].text.strip() if div else \"N/A\"\n",
    "\n",
    "            div_infos_sup = annonce_soup.find(\"div\", class_=\"sc-6p5md9-0 dsWaSi\")\n",
    "            Annee = div_infos_sup.find_all(\"span\")[0].text.strip() if div_infos_sup else \"N/A\"\n",
    "            Auto_manuel = div_infos_sup.find_all(\"span\")[1].text.strip() if div_infos_sup else \"N/A\"\n",
    "            Carburant = div_infos_sup.find_all(\"span\")[2].text.strip() if div_infos_sup else \"N/A\"\n",
    "\n",
    "            # Infos supplémentaires\n",
    "            div_infos_sup_2 = annonce_soup.find(\"ol\", class_=\"sc-qmn92k-3 hTEaGJ\")\n",
    "            try:\n",
    "                elements = div_infos_sup_2.find_all(\"li\") if div_infos_sup_2 else []\n",
    "                type_voiture = elements[0].find_all(\"span\")[1].text.strip() if len(elements) > 0 else \"N/A\"\n",
    "                secteur = elements[1].find_all(\"span\")[1].text.strip() if len(elements) > 1 else \"N/A\"\n",
    "                kilometrage = elements[2].find_all(\"span\")[1].text.strip() if len(elements) > 2 else \"N/A\"\n",
    "                marque = elements[3].find_all(\"span\")[1].text.strip() if len(elements) > 3 else \"N/A\"\n",
    "                modele = elements[4].find_all(\"span\")[1].text.strip() if len(elements) > 4 else \"N/A\"\n",
    "                n_portes = elements[5].find_all(\"span\")[1].text.strip() if len(elements) > 5 else \"N/A\"\n",
    "                origine = elements[6].find_all(\"span\")[1].text.strip() if len(elements) > 6 else \"N/A\"\n",
    "                p_main = elements[7].find_all(\"span\")[1].text.strip() if len(elements) > 7 else \"N/A\"\n",
    "                p_fiscale = elements[8].find_all(\"span\")[1].text.strip() if len(elements) > 8 else \"N/A\"\n",
    "                etat = elements[9].find_all(\"span\")[1].text.strip() if len(elements) > 9 else \"N/A\"\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Erreur extraction détails : {e}\")\n",
    "                type_voiture = secteur = kilometrage = marque = modele = n_portes = origine = p_main = p_fiscale = etat = \"N/A\"\n",
    "\n",
    "            # Stocker les données dans le CSV\n",
    "            writer.writerow([\n",
    "            titre,prix, date_ajout, localisation,Annee,Auto_manuel,Carburant, type_voiture, secteur, \n",
    "             kilometrage, marque, modele, n_portes, origine, p_main, \n",
    "             p_fiscale, etat,\n",
    "])\n",
    "\n",
    "            # Pause entre chaque annonce\n",
    "            time.sleep(4)\n",
    "\n",
    "        # Pause entre les pages\n",
    "        time.sleep(5)\n",
    "\n",
    "print(\"\\n✅ Scraping terminé et données enregistrées dans le fichier CSV !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Scraping de la page 41: https://www.avito.ma/fr/casablanca/voitures_d_occasion-%C3%A0_vendre?o=41\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/aïn_chock/voitures_d'occasion/Bmw_x5_très_bon_etat__55998716.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/anfa/voitures_d'occasion/Pajero_sport_full_option__55925987.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/ain_sebaa/voitures_d'occasion/Dacia_sandero_Diesel_manuelle_2024_à_Casablanca_56112194.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/aïn_chock/voitures_d'occasion/_Porsche___Macan_S_55958130.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/californie/voitures_d'occasion/Mercedes_Benz_Classe_GLE_300_D_Automatique_2020_56223383.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/aïn_chock/voitures_d'occasion/Dacia_sandero_steepway_diesel_première_main__56013563.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/sidi_moumen/voitures_d'occasion/Dacia_Logan__55844908.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/ain_sebaa/voitures_d'occasion/Lexus_LS_Hybride_Automatique_2019_à_Casablanca_55486257.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/derb_ghallef/voitures_d'occasion/mercedes_benz_classe_e_56130793.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/lissasfa/voitures_d'occasion/renault_clio_56164825.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/aïn_chock/voitures_d'occasion/Nissan_Qashqai_Diesel_Automatique_2020_55856524.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/californie/voitures_d'occasion/Volvo_XC60_Diesel_Automatique_2022_à_Casablanca_56222267.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/autre_secteur/voitures_d'occasion/mercedes_benz_classe_c_56055985.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/ain_sebaa/voitures_d'occasion/SKODA_FABIA_ESSENCE_MANUELLE_2020_A_casablanca_53752265.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/ain_sebaa/voitures_d'occasion/Renault_Express______56220592.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/oulfa/voitures_d'occasion/toyota_hilux_revo_56193009.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/maarif/voitures_d'occasion/Porsche_Cayenne_Coupé_Hybride_11_000_km_2024_55008596.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/ain_sebaa/voitures_d'occasion/Land_Rover_Range_Rover_Sport_Diesel_Automatique_55980261.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/ain_sebaa/voitures_d'occasion/seat_tarraco_55968719.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/ain_sebaa/voitures_d'occasion/HYUNDAI__TUCSON_1_6_CRDI_4X2_LUXE_ROUGE_56108915.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/centre_ville/voitures_d'occasion/Dacia_Sandero_Stepway__2022_56227389.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/ain_sebaa/voitures_d'occasion/Ford_Kuga_Diesel_Automatique_2021_53891204.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/bournazil/voitures_d'occasion/Renault_Clio_5_à_Casablanca_55846352.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/bournazil/voitures_d'occasion/Renault_clio_5_55574426.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/bournazil/voitures_d'occasion/Volkswagen_caddy__55592303.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/californie/voitures_d'occasion/Land_Rover_Range_Rover_Velar_Diesel_Automatique_56145732.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/ain_sebaa/voitures_d'occasion/CITROEN_BERLINGO_DIESEL_MANUELLE_2020_à_Casablanca_54642893.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/californie/voitures_d'occasion/Mercedes_Benz_Classe_E_Diesel_Automatique_2022_56140037.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/ain_sebaa/voitures_d'occasion/RENAULT_EXPRESS_AUTHENTIC__56108700.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/bournazil/voitures_d'occasion/Renault_clio_4_55589010.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/aïn_chock/voitures_d'occasion/hyundai_accent_56212212.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/les_princesses/voitures_d'occasion/Volvo_XC40_Diesel_Automatique_2019_à_Casablanca_56099109.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/anfa/voitures_d'occasion/Bentley_Bentayga_S_Hybride__2025_55138391.htm\n",
      "❌ Exception pour https://www.avito.ma/fr/anfa/voitures_d'occasion/Bentley_Bentayga_S_Hybride__2025_55138391.htm : HTTPSConnectionPool(host='www.avito.ma', port=443): Max retries exceeded with url: /fr/anfa/voitures_d'occasion/Bentley_Bentayga_S_Hybride__2025_55138391.htm (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001624018AEB0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/oulfa/voitures_d'occasion/jeep_renegade_56098154.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/aïn_chock/voitures_d'occasion/toyota_corolla_56112744.htm\n",
      "\n",
      "✅ Scraping terminé et données enregistrées dans le fichier CSV sans perte !\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Chemin du fichier CSV\n",
    "csv_file_path = r\"C:\\Users\\HP\\Desktop\\projet ai\\mini projet 2\\avito_voitures - Copy - Copy - Copy.csv\"\n",
    "\n",
    "# En-têtes CSV\n",
    "csv_headers = [\n",
    "    \"Titre\", \"Prix\", \"Date d'ajout\", \"Localisation\", \"Annee\", \"Auto_manuel\", \"Carburant\",\n",
    "    \"Type\", \"Secteur\", \"Kilométrage\", \"Marque\", \"Modèle\", \"Nombre de portes\",\n",
    "    \"Origine\", \"Première main\", \"Puissance fiscale\", \"État\",\n",
    "]\n",
    "\n",
    "# URL de base\n",
    "base_url = \"https://www.avito.ma/fr/casablanca/voitures_d_occasion-%C3%A0_vendre\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Fichier pour suivre la dernière page scrappée\n",
    "last_scraped_page_file = \"last_scraped_page.txt\"\n",
    "\n",
    "def get_page_content(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, allow_redirects=True)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            print(f\"❌ Erreur {response.status_code} sur : {url}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Exception pour {url} : {e}\")\n",
    "    return None\n",
    "\n",
    "def get_last_scraped_page():\n",
    "    if os.path.exists(last_scraped_page_file):\n",
    "        with open(last_scraped_page_file, \"r\") as f:\n",
    "            return int(f.read())\n",
    "    return 1  # Commencer par la première page si le fichier n'existe pas\n",
    "\n",
    "def save_last_scraped_page(page):\n",
    "    with open(last_scraped_page_file, \"w\") as f:\n",
    "        f.write(str(page))\n",
    "\n",
    "def clean_text(text):\n",
    "    if text:\n",
    "        return text.encode('utf-8').decode('utf-8').strip()\n",
    "    return None\n",
    "\n",
    "# Initialisation du CSV : si vide, écrire les headers\n",
    "if not os.path.exists(csv_file_path) or os.stat(csv_file_path).st_size == 0:\n",
    "    with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(csv_headers)\n",
    "\n",
    "# Scraper en mode ajout (append)\n",
    "with open(csv_file_path, mode='a', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    start_page = get_last_scraped_page()\n",
    "    pages_to_scrape = 1 # Tu peux modifier\n",
    "\n",
    "    for page in range(start_page, start_page + pages_to_scrape):\n",
    "        url = f\"{base_url}?o={page}\"\n",
    "        print(f\"\\n🔎 Scraping de la page {page}: {url}\")\n",
    "        page_content = get_page_content(url)\n",
    "        if not page_content:\n",
    "            continue\n",
    "\n",
    "        soup = BeautifulSoup(page_content, \"html.parser\")\n",
    "        div_principal = soup.find(\"div\", class_='sc-1nre5ec-1 crKvIr listing')\n",
    "        if not div_principal:\n",
    "            print(f\"⚠️ Pas d'annonces trouvées sur la page {page}\")\n",
    "            continue\n",
    "\n",
    "        annonces = div_principal.find_all(\"a\", href=True)\n",
    "        if not annonces:\n",
    "            print(f\"⚠️ Aucune annonce trouvée sur la page {page}\")\n",
    "            continue\n",
    "\n",
    "        for annonce in annonces:\n",
    "            annonce_url = annonce[\"href\"]\n",
    "            if annonce_url.startswith(\"/\"):\n",
    "                annonce_url = \"https://www.avito.ma\" + annonce_url\n",
    "\n",
    "            print(f\"📌 Traitement de l'annonce : {annonce_url}\")\n",
    "            annonce_content = get_page_content(annonce_url)\n",
    "            if not annonce_content:\n",
    "                continue\n",
    "\n",
    "            annonce_soup = BeautifulSoup(annonce_content, \"html.parser\")\n",
    "            div_annonce = annonce_soup.find(\"div\", class_=\"sc-1g3sn3w-8 ePtCCn\")\n",
    "            if not div_annonce:\n",
    "                print(f\"⚠️ Aucune donnée trouvée pour l'annonce {annonce_url}\")\n",
    "                continue\n",
    "\n",
    "            titre = div_annonce.find(\"h1\").text.strip() if div_annonce.find(\"h1\") else None\n",
    "            prix = div_annonce.find(\"p\").text.strip() if div_annonce.find(\"p\") else None\n",
    "            prix = None if prix and \"Prix non spécifié\" in prix else prix\n",
    "\n",
    "            div = annonce_soup.find(\"div\", class_=\"sc-1g3sn3w-7 bNWHpB\")\n",
    "            date_ajout = div.find_all(\"span\")[1].text.strip() if div else None\n",
    "            localisation = div.find_all(\"span\")[0].text.strip() if div else None\n",
    "\n",
    "            div_infos_sup = annonce_soup.find(\"div\", class_=\"sc-6p5md9-0 dsWaSi\")\n",
    "            Annee = div_infos_sup.find_all(\"span\")[0].text.strip() if div_infos_sup else None\n",
    "            Auto_manuel = div_infos_sup.find_all(\"span\")[1].text.strip() if div_infos_sup else None\n",
    "            Carburant = div_infos_sup.find_all(\"span\")[2].text.strip() if div_infos_sup else None\n",
    "\n",
    "            div_infos_sup_2 = annonce_soup.find(\"ol\", class_=\"sc-qmn92k-3 hTEaGJ\")\n",
    "            try:\n",
    "                elements = div_infos_sup_2.find_all(\"li\") if div_infos_sup_2 else []\n",
    "                type_voiture = elements[0].find_all(\"span\")[1].text.strip() if len(elements) > 0 else None\n",
    "                secteur = elements[1].find_all(\"span\")[1].text.strip() if len(elements) > 1 else None\n",
    "                kilometrage = elements[2].find_all(\"span\")[1].text.strip() if len(elements) > 2 else None\n",
    "                marque = elements[3].find_all(\"span\")[1].text.strip() if len(elements) > 3 else None\n",
    "                modele = elements[4].find_all(\"span\")[1].text.strip() if len(elements) > 4 else None\n",
    "                n_portes = elements[5].find_all(\"span\")[1].text.strip() if len(elements) > 5 else None\n",
    "                origine = elements[6].find_all(\"span\")[1].text.strip() if len(elements) > 6 else None\n",
    "                p_main = elements[7].find_all(\"span\")[1].text.strip() if len(elements) > 7 else None\n",
    "                p_fiscale = elements[8].find_all(\"span\")[1].text.strip() if len(elements) > 8 else None\n",
    "                etat = elements[9].find_all(\"span\")[1].text.strip() if len(elements) > 9 else None\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Erreur extraction détails : {e}\")\n",
    "                type_voiture = secteur = kilometrage = marque = modele = n_portes = origine = p_main = p_fiscale = etat = None\n",
    "\n",
    "            # Enregistrer l'annonce dans le CSV\n",
    "            writer.writerow([\n",
    "                clean_text(titre),\n",
    "                clean_text(prix),\n",
    "                clean_text(date_ajout),\n",
    "                clean_text(localisation),\n",
    "                clean_text(Annee),\n",
    "                clean_text(Auto_manuel),\n",
    "                clean_text(Carburant),\n",
    "                clean_text(type_voiture),\n",
    "                clean_text(secteur),\n",
    "                clean_text(kilometrage),\n",
    "                clean_text(marque),\n",
    "                clean_text(modele),\n",
    "                clean_text(n_portes),\n",
    "                clean_text(origine),\n",
    "                clean_text(p_main),\n",
    "                clean_text(p_fiscale),\n",
    "                clean_text(etat),\n",
    "            ])\n",
    "\n",
    "            # Pause entre les annonces\n",
    "            time.sleep(4)\n",
    "\n",
    "        # Sauvegarde de la dernière page\n",
    "        save_last_scraped_page(page)\n",
    "\n",
    "        # Pause entre les pages\n",
    "        time.sleep(5)\n",
    "\n",
    "print(\"\\n✅ Scraping terminé et données enregistrées dans le fichier CSV sans perte !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Scraping de la page 1: https://www.avito.ma/fr/casablanca/voitures_d_occasion-%C3%A0_vendre?o=1\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/Megane_3_coupé_56153271.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/bourgogne/voitures_d'occasion/Nissan_Juke_Automatique_2020_à_Casablanca_55599638.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/californie/voitures_d'occasion/Jeep_Wrangler_Sahara_Unlimited__56229993.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/belvédère/voitures_d'occasion/Toyota_Corolla_Hybride_Automatique_2020_56229898.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/Renault_arkana_full_2023_53878936.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/DACIA_SANDERO_56178015.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/autre_secteur/voitures_d'occasion/HYUNDAI_TUCSON_Diesel_Automatique_à_Casablanca__55875887.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/californie/voitures_d'occasion/Ford_Mustang_Cabriolet__Automatique_2022_ded_2025_56063590.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/Toyota_Rav4_hybride_Automatique_2020_à_Casablanca_55728073.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/ain_sebaa/voitures_d'occasion/Hyundai_Bayon_Essence_Automatique_2023_54626892.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/californie/voitures_d'occasion/Tesla_Model_3_Electrique_BVA_2023_Dédouané_2025_56088809.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/riviera/voitures_d'occasion/Audi_A3_Sportback_S_line_diesel_automatique_55908406.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/bourgogne/voitures_d'occasion/Volkswagen_Golf_8_GTI_2023_55610715.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/riviera/voitures_d'occasion/Opel_Corsa_Diesel_2024_à_Casablanca_55900218.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/belvédère/voitures_d'occasion/Toyota_C_HR_Hybride_Automatique_2022_55870505.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/Peugeot_407_Essence_tt_options_en_excellent_état__56230687.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/belvédère/voitures_d'occasion/Jeep_Renegade_Diesel_Auto_12_2019_à_Casablanca_56228661.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/Jeep_cherokee_night_Eagles__54876577.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/Range_sport_hse_diwana_55876564.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/Santafé_diesel_55274208.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/Accent_automatique__55731628.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/Clio_5_tt_option_54263009.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/Volkswagen_Golf_7_Diesel_Automatique_2017_56146280.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/Citroen_c3_56146272.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/Ford_fiesta_diesel_55576527.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/Glof_7_diesel_automatique__54985830.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/aïn_chock/voitures_d'occasion/Peugeot_3008_diesel_automatique__56213264.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/aïn_chock/voitures_d'occasion/Opel_Astra_Diesel__49337807.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/maârif_extension/voitures_d'occasion/Volkswagen_Coccinelle_Diesel_Automatique_2018_56186823.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/ain_sebaa/voitures_d'occasion/Land_Rover_Range_Rover_Velar_Diesel_Automatique_55547264.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/lissasfa/voitures_d'occasion/Hyundai_Elantra_Diesel__2020_55478583.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/Opel_adam_1er_main_55731615.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/aïn_chock/voitures_d'occasion/BMW_X1_09_2018_très_bonne_état_56237654.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/lissasfa/voitures_d'occasion/Dacia__Sandero__stepway_diesel__55479150.htm\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/autre_secteur/voitures_d'occasion/Ford_Kuga_fin_2018_peinture_d_origine_aucun_rotuch_56186904.htm\n",
      "\n",
      "🔎 Scraping de la page 2: https://www.avito.ma/fr/casablanca/voitures_d_occasion-%C3%A0_vendre?o=2\n",
      "📌 Traitement de l'annonce : https://www.avito.ma/fr/2_mars/voitures_d'occasion/Opel_adam_1er_main_55731615.htm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 152\u001b[0m\n\u001b[0;32m    132\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow([\n\u001b[0;32m    133\u001b[0m         clean_text(titre),\n\u001b[0;32m    134\u001b[0m         clean_text(prix),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m         clean_text(etat),\n\u001b[0;32m    150\u001b[0m     ])\n\u001b[0;32m    151\u001b[0m     csvfile\u001b[38;5;241m.\u001b[39mflush()  \u001b[38;5;66;03m# Pour éviter la perte des données en cas de crash\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pause entre chaque annonce\u001b[39;00m\n\u001b[0;32m    154\u001b[0m save_last_scraped_page(page)  \u001b[38;5;66;03m# Sauvegarde de la page actuelle\u001b[39;00m\n\u001b[0;32m    155\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Pause entre les pages\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Chemin du fichier CSV\n",
    "csv_file_path = r\"C:\\Users\\HP\\Desktop\\projet ai\\mini projet 2\\avito_voitures.csv\"\n",
    "\n",
    "# En-têtes CSV\n",
    "csv_headers = [\n",
    "    \"Titre\", \"Prix\", \"Date d'ajout\", \"Localisation\", \"Annee\", \"Auto_manuel\", \"Carburant\",\n",
    "    \"Type\", \"Secteur\", \"Kilométrage\", \"Marque\", \"Modèle\", \"Nombre de portes\",\n",
    "    \"Origine\", \"Première main\", \"Puissance fiscale\", \"État\",\n",
    "]\n",
    "\n",
    "base_url = \"https://www.avito.ma/fr/casablanca/voitures_d_occasion-%C3%A0_vendre\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "last_scraped_page_file = \"last_scraped_page.txt\"\n",
    "\n",
    "def get_page_content(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, allow_redirects=True)\n",
    "        if response.status_code == 200:\n",
    "            response.encoding = 'utf-8'  # Force encoding to UTF-8\n",
    "            return response.text\n",
    "        else:\n",
    "            print(f\"❌ Erreur {response.status_code} sur : {url}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Exception pour {url} : {e}\")\n",
    "    return None\n",
    "\n",
    "def get_last_scraped_page():\n",
    "    if os.path.exists(last_scraped_page_file):\n",
    "        with open(last_scraped_page_file, \"r\") as f:\n",
    "            return int(f.read())\n",
    "    return 1\n",
    "\n",
    "def save_last_scraped_page(page):\n",
    "    with open(last_scraped_page_file, \"w\") as f:\n",
    "        f.write(str(page))\n",
    "\n",
    "def clean_text(text):\n",
    "    if text:\n",
    "        # Supprimer les espaces insécables, les retours à la ligne, les tabulations et espaces superflus\n",
    "        cleaned = text.replace('\\u202f', ' ').replace('\\xa0', ' ').replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "        cleaned = re.sub(' +', ' ', cleaned)  # Remplace plusieurs espaces par un seul\n",
    "        return cleaned.strip()\n",
    "    return None\n",
    "\n",
    "# Initialisation du CSV : si vide, écrire les headers\n",
    "if not os.path.exists(csv_file_path) or os.stat(csv_file_path).st_size == 0:\n",
    "    with open(csv_file_path, mode='w', newline='', encoding='utf-8-sig') as csvfile:  # Use utf-8-sig for proper encoding in CSV\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(csv_headers)\n",
    "\n",
    "# Scraping et sauvegarde continue\n",
    "with open(csv_file_path, mode='a', newline='', encoding='utf-8-sig') as csvfile:  # Use utf-8-sig for proper encoding in CSV\n",
    "    writer = csv.writer(csvfile)\n",
    "    start_page = get_last_scraped_page()\n",
    "    pages_to_scrape = 340  # Modifier selon le besoin\n",
    "\n",
    "    for page in range(start_page, start_page + pages_to_scrape):\n",
    "        url = f\"{base_url}?o={page}\"\n",
    "        print(f\"\\n🔎 Scraping de la page {page}: {url}\")\n",
    "        page_content = get_page_content(url)\n",
    "        if not page_content:\n",
    "            continue\n",
    "\n",
    "        soup = BeautifulSoup(page_content, \"html.parser\")  # Removed from_encoding='utf-8'\n",
    "        div_principal = soup.find(\"div\", class_='sc-1nre5ec-1 crKvIr listing')\n",
    "        if not div_principal:\n",
    "            print(f\"⚠️ Pas d'annonces trouvées sur la page {page}\")\n",
    "            continue\n",
    "\n",
    "        annonces = div_principal.find_all(\"a\", href=True)\n",
    "        if not annonces:\n",
    "            print(f\"⚠️ Aucune annonce trouvée sur la page {page}\")\n",
    "            continue\n",
    "\n",
    "        for annonce in annonces:\n",
    "            annonce_url = annonce[\"href\"]\n",
    "            if annonce_url.startswith(\"/\"):\n",
    "                annonce_url = \"https://www.avito.ma\" + annonce_url\n",
    "\n",
    "            print(f\"📌 Traitement de l'annonce : {annonce_url}\")\n",
    "            annonce_content = get_page_content(annonce_url)\n",
    "            if not annonce_content:\n",
    "                continue\n",
    "\n",
    "            annonce_soup = BeautifulSoup(annonce_content, \"html.parser\")  # Removed from_encoding='utf-8'\n",
    "            div_annonce = annonce_soup.find(\"div\", class_=\"sc-1g3sn3w-8 ePtCCn\")\n",
    "            if not div_annonce:\n",
    "                print(f\"⚠️ Aucune donnée trouvée pour l'annonce {annonce_url}\")\n",
    "                continue\n",
    "\n",
    "            titre = div_annonce.find(\"h1\").text if div_annonce.find(\"h1\") else None\n",
    "            prix = div_annonce.find(\"p\").text if div_annonce.find(\"p\") else None\n",
    "            prix = None if prix and \"Prix non spécifié\" in prix else prix\n",
    "\n",
    "            div = annonce_soup.find(\"div\", class_=\"sc-1g3sn3w-7 bNWHpB\")\n",
    "            date_ajout = div.find_all(\"span\")[1].text if div else None\n",
    "            localisation = div.find_all(\"span\")[0].text if div else None\n",
    "\n",
    "            div_infos_sup = annonce_soup.find(\"div\", class_=\"sc-6p5md9-0 dsWaSi\")\n",
    "            Annee = div_infos_sup.find_all(\"span\")[0].text if div_infos_sup else None\n",
    "            Auto_manuel = div_infos_sup.find_all(\"span\")[1].text if div_infos_sup else None\n",
    "            Carburant = div_infos_sup.find_all(\"span\")[2].text if div_infos_sup else None\n",
    "\n",
    "            div_infos_sup_2 = annonce_soup.find(\"ol\", class_=\"sc-qmn92k-3 hTEaGJ\")\n",
    "            try:\n",
    "                elements = div_infos_sup_2.find_all(\"li\") if div_infos_sup_2 else []\n",
    "                type_voiture = elements[0].find_all(\"span\")[1].text if len(elements) > 0 else None\n",
    "                secteur = elements[1].find_all(\"span\")[1].text if len(elements) > 1 else None\n",
    "                kilometrage = elements[2].find_all(\"span\")[1].text if len(elements) > 2 else None\n",
    "                marque = elements[3].find_all(\"span\")[1].text if len(elements) > 3 else None\n",
    "                modele = elements[4].find_all(\"span\")[1].text if len(elements) > 4 else None\n",
    "                n_portes = elements[5].find_all(\"span\")[1].text if len(elements) > 5 else None\n",
    "                origine = elements[6].find_all(\"span\")[1].text if len(elements) > 6 else None\n",
    "                p_main = elements[7].find_all(\"span\")[1].text if len(elements) > 7 else None\n",
    "                p_fiscale = elements[8].find_all(\"span\")[1].text if len(elements) > 8 else None\n",
    "                etat = elements[9].find_all(\"span\")[1].text if len(elements) > 9 else None\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Erreur extraction détails : {e}\")\n",
    "                type_voiture = secteur = kilometrage = marque = modele = n_portes = origine = p_main = p_fiscale = etat = None\n",
    "\n",
    "            # Enregistrement de l'annonce dans le CSV avec nettoyage\n",
    "            writer.writerow([\n",
    "                clean_text(titre),\n",
    "                clean_text(prix),\n",
    "                clean_text(date_ajout),\n",
    "                clean_text(localisation),\n",
    "                clean_text(Annee),\n",
    "                clean_text(Auto_manuel),\n",
    "                clean_text(Carburant),\n",
    "                clean_text(type_voiture),\n",
    "                clean_text(secteur),\n",
    "                clean_text(kilometrage),\n",
    "                clean_text(marque),\n",
    "                clean_text(modele),\n",
    "                clean_text(n_portes),\n",
    "                clean_text(origine),\n",
    "                clean_text(p_main),\n",
    "                clean_text(p_fiscale),\n",
    "                clean_text(etat),\n",
    "            ])\n",
    "            csvfile.flush()  # Pour éviter la perte des données en cas de crash\n",
    "            time.sleep(4)  # Pause entre chaque annonce\n",
    "\n",
    "        save_last_scraped_page(page)  # Sauvegarde de la page actuelle\n",
    "        time.sleep(5)  # Pause entre les pages\n",
    "\n",
    "print(\"\\n✅ Scraping terminé et toutes les données sont nettoyées et sauvegardées correctement dans le CSV !\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
